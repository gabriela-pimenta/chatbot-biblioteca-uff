# -*- coding: utf-8 -*-
"""projeto_Imersão IA Alura + Gemini.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x-pwDWLwEcvCXRz3xnqrVy9jZpZFhNQW
"""

import getpass
import google.generativeai as genai

def configurar_api_key():
  """Solicita a API key do usuário e configura a biblioteca."""
  api_key = getpass.getpass("Por favor, insira sua API key do Google Gemini e pressione Enter:")
  genai.configure(api_key=api_key)
  print("API key configurada com sucesso para esta sessão.")

# Chame a função para configurar a API key
configurar_api_key()

!pip install google-generativeai pdfplumber

!pip install google-generativeai pdfplumber PyPDF2

import google.generativeai as genai
from google.colab import userdata # Para acessar os secrets
import pdfplumber
from google.colab import files # Para fazer upload de arquivos
import io # Para manipular os bytes do arquivo em memória

# Tenta carregar a API Key a partir dos Secrets do Colab
try:
    GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash-latest') # Você pode escolher o modelo Gemini, ex: 'gemini-pro' ou 'gemini-1.5-flash-latest'
    print("API Key configurada e modelo Gemini inicializado com sucesso!")
except userdata.SecretNotFoundError:
    print("ERRO CRÍTICO: A API Key do Google (GOOGLE_API_KEY) não foi encontrada nos Secrets do Colab.")
    print("Por favor, adicione sua GOOGLE_API_KEY aos Secrets do Colab (ícone de chave no painel esquerdo) com o nome 'GOOGLE_API_KEY'.")
    print("Certifique-se de que o nome está EXATAMENTE como 'GOOGLE_API_KEY'.")
except Exception as e:
    print(f"Ocorreu um erro ao configurar a API Key ou inicializar o modelo: {e}")

def extract_text_from_pdf(pdf_file_content):
    """
    Extrai texto de um conteúdo de arquivo PDF em bytes.
    """
    text = ""
    try:
        # Abre o conteúdo do PDF (que está em bytes) como se fosse um arquivo
        with io.BytesIO(pdf_file_content) as pdf_stream:
            # Usa pdfplumber para abrir o "arquivo" PDF a partir do stream de bytes
            with pdfplumber.open(pdf_stream) as pdf:
                for page_number, page in enumerate(pdf.pages):
                    page_text = page.extract_text()
                    if page_text:
                        text += f"\n--- Página {page_number + 1} ---\n" # Adiciona um separador de página
                        text += page_text + "\n"
        return text.strip() # Remove espaços em branco extras no início e no fim
    except Exception as e:
        print(f"Erro ao extrair texto do PDF: {e}")
        return None

# Solicita o upload do arquivo PDF
print("Por favor, faça o upload de um arquivo PDF contendo regulamentos ou tutoriais da biblioteca:")
uploaded_file_data = files.upload() # Abre a janela de diálogo para upload

extracted_pdf_text = None # Inicializa a variável
if uploaded_file_data:
    # Pega o nome do primeiro arquivo carregado (assumindo um único arquivo)
    file_name = next(iter(uploaded_file_data))
    print(f"\nArquivo '{file_name}' carregado com sucesso.")

    # Pega o conteúdo do arquivo carregado (em bytes)
    pdf_content_bytes = uploaded_file_data[file_name]

    # Extrai o texto do conteúdo do PDF
    extracted_pdf_text = extract_text_from_pdf(pdf_content_bytes)

    if extracted_pdf_text:
        print("\nTexto extraído do PDF com sucesso!")
        # Para visualização, podemos mostrar uma parte do texto:
        # print("\n--- Início de um trecho do Texto do PDF ---")
        # print(extracted_pdf_text[:1000] + "..." if len(extracted_pdf_text) > 1000 else extracted_pdf_text)
        # print("--- Fim do trecho do Texto do PDF ---")
    else:
        print("Não foi possível extrair texto do PDF. Verifique se o arquivo é um PDF válido e não está corrompido ou protegido contra cópia.")
else:
    print("Nenhum arquivo PDF foi carregado.")

import google.generativeai as genai

# Se você reiniciou o Colab, pode precisar reconfigurar a chave novamente


for m in genai.list_models():
  print(f"Nome do Modelo: {m.name}")
  if m.versions:
    for version in m.versions:
      print(f"  Versão: {version.name}")
      print(f"    Status: {version.status}")
  print(f"  Métodos Suportados: {m.supported_generation_methods}")
  print("-" * 30)

if extracted_pdf_text: # Verifica se o texto foi extraído com sucesso
    user_question = input("\nDigite sua pergunta sobre o conteúdo do PDF (ex: 'Qual o regulamento para empréstimo?'): ")

    if user_question:
        # Montando o prompt para o modelo Gemini
        # Este prompt instrui o modelo sobre como ele deve se comportar
        prompt_template = f"""
        Você é um assistente de chatbot especializado em responder perguntas sobre os documentos de bibliotecas da UFF.
        Use SOMENTE o "Texto do Documento" fornecido abaixo para responder à "Pergunta do Usuário".
        Se a informação para responder à pergunta não estiver claramente presente no "Texto do Documento",
        responda: "Desculpe, não encontrei essa informação específica no documento fornecido."
        Não invente informações que não estão no texto. Seja direto e conciso.

        Texto do Documento:
        ---
        {extracted_pdf_text}
        ---

        Pergunta do Usuário: {user_question}

        Resposta do Assistente:
        """

        try:
            print("\nEnviando sua pergunta para o modelo Gemini. Aguarde um momento...")
            # Envia o prompt para o modelo Gemini
            response = model.generate_content(prompt_template)

            print("\nResposta do Chatbot:")
            print(response.text)

        except Exception as e:
            print(f"Ocorreu um erro ao tentar gerar a resposta com o Gemini: {e}")
            if "GOOGLE_API_KEY" in str(e).upper(): # Verifica se o erro pode ser de API Key
                 print("DICA: Verifique se sua GOOGLE_API_KEY está correta, ativa e foi adicionada corretamente aos Secrets do Colab.")
            elif "quota" in str(e).lower(): # Verifica se o erro pode ser de cota
                 print("DICA: Você pode ter atingido o limite de uso (quota) da API. Verifique seu painel no Google AI Studio ou Google Cloud.")

    else:
        print("Nenhuma pergunta foi digitada.")
else:
    print("\nNão há texto de PDF disponível para fazer perguntas. Por favor, execute a célula anterior para carregar um PDF.")

import PyPDF2
import os

def ler_pdfs_da_pasta(caminho_pasta):
  texto_completo = ""
  for nome_arquivo in os.listdir(caminho_pasta):
    if nome_arquivo.endswith(".pdf"):
      caminho_completo = os.path.join(caminho_pasta, nome_arquivo)
      try:
        with open(caminho_completo, 'rb') as arquivo:
          leitor_pdf = PyPDF2.PdfReader(arquivo)
          for pagina_num in range(len(leitor_pdf.pages)):
            pagina = leitor_pdf.pages[pagina_num]
            texto_completo += pagina.extract_text() + "\n\n" # Adiciona separação entre documentos
      except FileNotFoundError:
        print(f"Erro: Arquivo não encontrado: {caminho_completo}")
      except Exception as e:
        print(f"Erro ao ler {caminho_completo}: {e}")
  return texto_completo

# Especifique o nome da pasta onde você colocou os PDFs
pasta_pdfs = "documentos_biblioteca"

# Crie a pasta se ela não existir
if not os.path.exists(pasta_pdfs):
    os.makedirs(pasta_pdfs)
    print(f"Pasta '{pasta_pdfs}' criada. Por favor, faça o upload dos seus PDFs para esta pasta.")
else:
    conteudo_total_pdfs = ler_pdfs_da_pasta(pasta_pdfs)

    if conteudo_total_pdfs:
        print(f"Conteúdo total dos PDFs (primeiros 200 caracteres): {conteudo_total_pdfs[:200]}...")
    else:
        print("Nenhum arquivo PDF encontrado na pasta ou ocorreu um erro ao ler os arquivos.")

import google.generativeai as genai

# Já configuramos a API key anteriormente, então não precisamos fazer isso de novo nesta sessão.
# Certifique-se de que a configuração ainda está ativa se você reiniciou o Colab.

# Mude o nome do modelo para um que você tem quota disponível, como 'gemini-1.5-flash-latest'
model = genai.GenerativeModel('gemini-1.5-flash-latest')

pergunta = "Quais são os documentos necessários para o cadastro nas bibliotecas?"

# Verifique se a variável 'conteudo_total_pdfs' existe e não está vazia antes de usar
if 'conteudo_total_pdfs' in locals() and conteudo_total_pdfs:
    try:
        # Envia a pergunta para o modelo configurado
        resposta = model.generate_content(f"Responda à seguinte pergunta usando APENAS as informações contidas neste texto: '{conteudo_total_pdfs}'.\n\nPergunta: {pergunta}")

        print(resposta.text)

    except Exception as e:
        print(f"Ocorreu um erro ao tentar gerar a resposta com o Gemini: {e}")
        # Mensagens de dica para erros comuns
        if "GOOGLE_API_KEY" in str(e).upper():
             print("DICA: Verifique se sua GOOGLE_API_KEY está correta, ativa e foi adicionada corretamente aos Secrets do Colab.")
        elif "quota" in str(e).lower():
             print("DICA: Você pode ter atingido o limite de uso (quota) da API. Verifique seu painel no Google AI Studio ou Google Cloud.")
        elif "models/" in str(e) and "is not found" in str(e):
            print("DICA: O nome do modelo pode estar incorreto ou o modelo não está disponível para sua conta ou região. Verifique a lista de modelos disponíveis via genai.list_models().")
        else:
            print("DICA: Verifique a mensagem de erro para mais detalhes ou consulte a documentação da API do Google Gemini.")

else:
    print("Variável 'conteudo_total_pdfs' não encontrada ou vazia. Certifique-se de ter executado a célula que lê os arquivos PDF da pasta.")

texto_do_site_pre_cadastro = """
O pré-cadastro é para alunos, professores e servidores da UFF.
Ao se cadastrar, você recebe um login e senha para o Pergamum-UFF.
O formulário pede: nome completo, e-mail, tipo de vínculo, comprovante de inscrição, telefone, endereço, RG, CPF, data de nascimento, nacionalidade e curso.
Você declara que as informações são válidas e que seus dados serão usados no Pergamum-UFF para acesso aos serviços online das bibliotecas.
Usuários da Creche e do Coluni devem ir diretamente às bibliotecas responsáveis (BFP e BML).
"""

# Certifique-se de que 'conteudo_total_pdfs' foi preenchido corretamente
if 'conteudo_total_pdfs' in locals():
  conteudo_completo = conteudo_total_pdfs + "\n\n" + texto_do_site_pre_cadastro
  print("Conteúdo dos PDFs e do site combinado com sucesso.")
else:
  print("A variável 'conteudo_total_pdfs' não foi definida. Execute a leitura dos PDFs primeiro!")
  conteudo_completo = texto_do_site_pre_cadastro # Usar apenas o texto do site por enquanto

import google.generativeai as genai

# Certifique-se de que sua API key está configurada (execute a célula de configuração se necessário)


model = genai.GenerativeModel('models/gemini-1.5-flash-latest')

pergunta_pre_cadastro = "quais os produtos e serviços?"

resposta_pre_cadastro = model.generate_content(f"Responda à seguinte pergunta usando APENAS as informações contidas neste texto: '{conteudo_completo}'.\n\nPergunta: {pergunta_pre_cadastro}")

print("\nResposta sobre o pré-cadastro:")
print(resposta_pre_cadastro.text)

texto_ficha_catalografica_bcg = """
Para gerar a ficha catalográfica na BCG, o usuário deve preencher um formulário online, atentando para o preenchimento correto dos campos, já que toda informação inserida é de responsabilidade do usuário.
Após o preenchimento, ao clicar em “Gerar ficha”, uma nova página do navegador será aberta com a ficha catalográfica gerada.
O usuário poderá realizar o download do arquivo em formato PDF e inserir no trabalho ou tirar um “print” da imagem da ficha e colar no arquivo do trabalho.
Para informações mais detalhadas de como preencher e gerar a ficha catalográfica, o usuário pode acessar as Orientações básicas para preenchimento e geração da ficha catalográfica no link: https://bibliotecas.uff.br/bcg/fichacatalografica/.
"""

texto_funcionamento_bcg = """
A Biblioteca Central do Gragoatá (BCG) funciona de segunda a sexta-feira, das 8h às 20h.
"""

texto_produtos_servicos = """
As Bibliotecas da UFF oferecem uma variedade de produtos e serviços, incluindo acesso a coleções impressas e digitais, assistência para usuários com deficiência e um boletim bibliográfico que lista novas aquisições.
Os usuários podem se cadastrar para acessar os serviços através do Sistema Pergamum, consultar o catálogo online e obter cópias de documentos técnico-científicos de bibliotecas brasileiras e internacionais.
Adicionalmente, as bibliotecas oferecem disseminação seletiva de informação, acesso a e-books, empréstimos domiciliares, empréstimos entre bibliotecas e ferramentas de pesquisa.
As Bibliotecas da UFF também possuem um canal no YouTube que oferece materiais audiovisuais e tutoriais.
"""

# Certifique-se de que todas as variáveis de texto estão definidas
if 'conteudo_total_pdfs' in locals():
  conteudo_completo = conteudo_total_pdfs + "\n\n"
else:
  conteudo_completo = ""

if 'texto_do_site_pre_cadastro' in locals():
  conteudo_completo += texto_do_site_pre_cadastro + "\n\n"

if 'texto_produtos_servicos' in locals():
  conteudo_completo += texto_produtos_servicos + "\n\n"
else:
  print("A variável 'texto_produtos_servicos' não foi definida. Adicione o texto dos produtos e serviços!")

conteudo_completo += texto_ficha_catalografica_bcg + "\n\n"
conteudo_completo += texto_funcionamento_bcg

print("Todo o conteúdo foi combinado com sucesso.")

import google.generativeai as genai
import textwrap

# Certifique-se de que sua API key está configurada


model = genai.GenerativeModel('models/gemini-1.5-flash-latest')

# Largura desejada para a quebra de linha
largura_tela = 70

# Certifique-se de que 'conteudo_completo' está definido
if 'conteudo_completo' not in locals():
  print("A variável 'conteudo_completo' não foi definida. Execute as células de leitura e combinação de informações primeiro!")
else:
  print("Chatbot das Bibliotecas da UFF iniciado. Digite sua pergunta ou 'sair' para encerrar.")
  while True:
    pergunta_usuario = input("Você: ")
    if pergunta_usuario.lower() == 'sair':
      break

    prompt_com_contexto = f"Responda à seguinte pergunta usando APENAS as informações contidas neste texto: '{conteudo_completo}'.\n\nPergunta: {pergunta_usuario}"

    try:
      resposta = model.generate_content(prompt_com_contexto)
      # Formatar a saída com quebras de linha
      texto_formatado = textwrap.fill(resposta.text, width=largura_tela)
      print(f"Chatbot: {texto_formatado}")
    except Exception as e:
      print(f"Ocorreu um erro ao gerar a resposta: {e}")

  print("Chatbot encerrado.")